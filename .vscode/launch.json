{
    // Use IntelliSense to learn about possible attributes.
    // Hover to view descriptions of existing attributes.
    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [  
        {
            "name": "Python: Current File with no cuda-env-config",
            "type": "debugpy",
            "request": "launch",
            "program": "${file}",
            "console": "integratedTerminal",
            "justMyCode": false
        },
        //---------------------------------------------------------------------
        {
            "name": "Python: Train Distributedly",
            "type": "debugpy",
            "request": "launch",
            "program": "", // which torchrun
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYDEVD_DISABLE_FILE_VALIDATION": "1",
                "WANDB_MODE": "disabled",
                "CUDA_VISIBLE_DEVICES": "0,1",
            },
            "args": [
                "--nproc_per_node=2",
                "--master_port=29599",
                "train.py",
                "config.main=configs/templates/train.yaml",
                "special.debug=normal",
                "special.save_current_project=False",
                // "special.no_logger=True",
                // "special.single_eval=True",
                "trainer.trainer_batch_size_per_rank=2",
                "env.num_workers=0",
            ],
        },
        //---------------------------------------------------------------------
        {
            "name": "Python: Train on One GPU",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/train.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "WANDB_MODE": "disabled",
                "CUDA_VISIBLE_DEVICES": "0",
            },
            "args": [
                "config.main=configs/templates/train.yaml",
                "special.debug=normal",
                "special.save_current_project=False",
                // "special.no_logger=True",
                // "special.single_eval=True",
                "trainer.trainer_batch_size_per_rank=2",
                "env.num_workers=0",
            ],
        },
        //---------------------------------------------------------------------
        {
            "name": "Python: Train on CPU",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/train.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "WANDB_MODE": "disabled",
            },
            "args": [
                "env.device=cpu",
                "config.main=configs/templates/train.yaml",
                "special.debug=normal",
                "special.save_current_project=False",
                // "special.no_logger=True",
                "tester.tester_batch_size_per_rank=1",
                "env.num_workers=0",
            ],
        },
        //---------------------------------------------------------------------
                {
            "name": "Python: Inference Distributedly",
            "type": "debugpy",
            "request": "launch",
            "program": "", // which torchrun
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "PYDEVD_DISABLE_FILE_VALIDATION": "1",
                "WANDB_MODE": "disabled",
                "CUDA_VISIBLE_DEVICES": "0,1",
            },
            "args": [
                "--nproc_per_node=2",
                "--master_port=29599",
                "inference.py",
                "config.main=configs/defaults/inference.yaml",
                "special.debug=normal",
                "special.save_current_project=False",
                // "special.no_logger=True",
                "tester.tester_batch_size_per_rank=1",
                "env.num_workers=0",
            ],
        },
        //---------------------------------------------------------------------
        {
            "name": "Python: Inference on One GPU ",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/inference.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "WANDB_MODE": "disabled",
                "CUDA_VISIBLE_DEVICES": "0",
            },
            "args": [
                "config.main=configs/defaults/inference.yaml",
                "special.debug=normal",
                "special.save_current_project=False",
                // "special.no_logger=True",
                // "special.single_eval=True",
                "tester.tester_batch_size_per_rank=1",
                "env.num_workers=0",
            ],
        },
        //---------------------------------------------------------------------
        {
            "name": "Python: Inference on CPU",
            "type": "debugpy",
            "request": "launch",
            "program": "${workspaceFolder}/inference.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "env": {
                "WANDB_MODE": "disabled",
            },
            "args": [
                "env.device=cpu",
                "config.main=configs/defaults/inference.yaml",
                "special.debug=normal",
                "special.save_current_project=False",
                // "special.no_logger=True",
                "tester.tester_batch_size_per_rank=1",
                "env.num_workers=0",
            ],
        },
    ]
}